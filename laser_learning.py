"""
ë ˆì´ì € ìë™ ê²€ì¶œ ë° í•™ìŠµ ì‹œìŠ¤í…œ
í”„ë¡œì í„° ìŠ¤í¬ë¦°ì—ì„œ ë¯¸ì„¸í•œ ë ˆì´ì € ì ì„ ìë™ìœ¼ë¡œ ì°¾ê³  í•™ìŠµ
"""
import matplotlib
matplotlib.use('Agg')
import cv2
import numpy as np
import os
import json
import pickle
from datetime import datetime
from typing import List, Tuple, Dict, Optional
from dataclasses import dataclass, asdict
from tqdm import tqdm
import matplotlib.pyplot as plt
from scipy import stats
from sklearn.cluster import DBSCAN

@dataclass
class LaserPoint:
    """ê²€ì¶œëœ ë ˆì´ì € í¬ì¸íŠ¸ ì •ë³´"""
    x: int
    y: int
    confidence: float
    brightness: float
    green_ratio: float
    contrast: float
    image_id: str

class LaserAutoLearner:
    """ë ˆì´ì € ìë™ ê²€ì¶œ ë° í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self, data_dir: str = "./data"):
        self.data_dir = data_dir
        self.on_dir = os.path.join(data_dir, "images_on")
        self.off_dir = os.path.join(data_dir, "images_off")
        self.processed_dir = os.path.join(data_dir, "processed")
        
        # ê²€ì¶œëœ ë ˆì´ì € í¬ì¸íŠ¸ë“¤
        self.detected_points: List[LaserPoint] = []
        
        # í•™ìŠµëœ íŒŒë¼ë¯¸í„°
        self.learned_params = {
            'brightness_range': (0, 255),
            'green_ratio_range': (0.0, 1.0),
            'contrast_range': (0, 255),
            'avg_position': (0, 0),
            'position_std': 0,
            'confidence_threshold': 0.5
        }
        
        # í†µê³„ ì •ë³´
        self.stats = {
            'total_pairs': 0,
            'detected_count': 0,
            'failed_count': 0,
            'avg_confidence': 0.0
        }
        
        os.makedirs(self.processed_dir, exist_ok=True)
    
    def load_image_pairs(self) -> List[Tuple[np.ndarray, np.ndarray, str]]:
        """ON/OFF ì´ë¯¸ì§€ ìŒ ë¡œë“œ"""
        on_files = sorted([f for f in os.listdir(self.on_dir) if f.endswith(('.jpg', '.png'))])
        off_files = sorted([f for f in os.listdir(self.off_dir) if f.endswith(('.jpg', '.png'))])
        
        pairs = []
        for on_file in on_files:
            # ë§¤ì¹­ë˜ëŠ” OFF íŒŒì¼ ì°¾ê¸° (íŒŒì¼ëª… ê¸°ì¤€)
            base_name = on_file.replace('_on', '').replace('on_', '')
            matching_off = None
            
            for off_file in off_files:
                if base_name in off_file or off_file.replace('_off', '').replace('off_', '') == base_name:
                    matching_off = off_file
                    break
            
            if matching_off:
                on_path = os.path.join(self.on_dir, on_file)
                off_path = os.path.join(self.off_dir, matching_off)
                
                on_img = cv2.imread(on_path)
                off_img = cv2.imread(off_path)
                
                if on_img is not None and off_img is not None:
                    pairs.append((on_img, off_img, on_file))
                    print(f"âœ… ë¡œë“œ: {on_file} <-> {matching_off}")
        
        print(f"\nì´ {len(pairs)}ê°œ ì´ë¯¸ì§€ ìŒ ë¡œë“œ ì™„ë£Œ")
        return pairs
    
    def detect_laser_difference(self, on_img: np.ndarray, off_img: np.ndarray) -> Optional[LaserPoint]:
        """íˆíŠ¸ë§µ ê¸°ë°˜ ë‹¨ìˆœ ê²€ì¶œ"""
        diff = cv2.absdiff(on_img, off_img)
        gray_diff = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
        blurred = cv2.GaussianBlur(gray_diff, (15, 15), 0)
        
        _, max_val, _, max_loc = cv2.minMaxLoc(blurred)
        
        if max_val < 10:  # ìµœì†Œ ì„ê³„ê°’
            return None
            
        x, y = max_loc
        
        # ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œ (ê¸°ì¡´ ë°©ì‹ ì¬ì‚¬ìš©)
        features = self._extract_features(on_img, off_img, x, y)
        if not features:
            return None
            
        return LaserPoint(
            x=x, y=y,
            confidence=features['confidence'],
            brightness=features['brightness'], 
            green_ratio=features['green_ratio'],
            contrast=features['contrast'],
            image_id=""
        )
    
    def _extract_features(self, on_img: np.ndarray, off_img: np.ndarray, 
                         x: int, y: int) -> Optional[Dict]:
        """ë ˆì´ì € ìœ„ì¹˜ì—ì„œ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            # ROI ì¶”ì¶œ (5x5 ì˜ì—­)
            roi_size = 2
            x1, y1 = max(0, x-roi_size), max(0, y-roi_size)
            x2, y2 = min(on_img.shape[1], x+roi_size+1), min(on_img.shape[0], y+roi_size+1)
            
            on_roi = on_img[y1:y2, x1:x2]
            off_roi = off_img[y1:y2, x1:x2]
            
            # ON ì´ë¯¸ì§€ì—ì„œì˜ ìµœëŒ€ ë°ê¸°
            on_gray = cv2.cvtColor(on_roi, cv2.COLOR_BGR2GRAY)
            on_brightness = np.max(on_gray)
            
            # OFF ì´ë¯¸ì§€ì—ì„œì˜ í‰ê·  ë°ê¸°
            off_gray = cv2.cvtColor(off_roi, cv2.COLOR_BGR2GRAY)
            off_brightness = np.mean(off_gray)
            
            # ëŒ€ë¹„ (ì°¨ì´)
            contrast = on_brightness - off_brightness
            
            # ì¤‘ì‹¬ í”½ì…€ì˜ ìƒ‰ìƒ ì •ë³´
            center_bgr = on_img[y, x]
            b, g, r = float(center_bgr[0]), float(center_bgr[1]), float(center_bgr[2])
            
            # ë…¹ìƒ‰ ë¹„ìœ¨
            total = b + g + r
            green_ratio = g / total if total > 0 else 0
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_confidence(contrast, green_ratio, on_brightness)
            
            return {
                'brightness': on_brightness,
                'green_ratio': green_ratio,
                'contrast': contrast,
                'confidence': confidence
            }
            
        except Exception as e:
            print(f"íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None
    
    def _calculate_confidence(self, contrast: float, green_ratio: float, brightness: float) -> float:
        """ì‹ ë¢°ë„ ê³„ì‚°"""
        # ëŒ€ë¹„ ì ìˆ˜ (0~1)
        contrast_score = min(1.0, contrast / 50.0) if contrast > 0 else 0
        
        # ë…¹ìƒ‰ ë¹„ìœ¨ ì ìˆ˜ (0~1)
        green_score = min(1.0, max(0, (green_ratio - 0.3) / 0.3))
        
        # ë°ê¸° ì ìˆ˜ (0~1)
        brightness_score = min(1.0, brightness / 200.0) if brightness > 50 else 0
        
        # ê°€ì¤‘ í‰ê· 
        confidence = (contrast_score * 0.5 + green_score * 0.3 + brightness_score * 0.2)
        
        return confidence
    
    def process_all_pairs(self):
        """ëª¨ë“  ì´ë¯¸ì§€ ìŒ ì²˜ë¦¬"""
        print("\n=== ë ˆì´ì € ìë™ ê²€ì¶œ ì‹œì‘ ===")
        
        # ì´ë¯¸ì§€ ìŒ ë¡œë“œ
        pairs = self.load_image_pairs()
        self.stats['total_pairs'] = len(pairs)
        
        # ê° ìŒ ì²˜ë¦¬
        for on_img, off_img, img_id in tqdm(pairs, desc="ì²˜ë¦¬ì¤‘"):
            laser_point = self.detect_laser_difference(on_img, off_img)
            
            if laser_point:
                laser_point.image_id = img_id
                self.detected_points.append(laser_point)
                self.stats['detected_count'] += 1
                
                # ì‹œê°í™” ì €ì¥ (ì˜µì…˜)
                self._save_detection_result(on_img, off_img, laser_point)
            else:
                self.stats['failed_count'] += 1
                print(f"âš ï¸ ê²€ì¶œ ì‹¤íŒ¨: {img_id}")
        
        print(f"\nê²€ì¶œ ì™„ë£Œ: {self.stats['detected_count']}/{self.stats['total_pairs']}")
    
    def _save_detection_result(self, on_img: np.ndarray, off_img: np.ndarray, point: LaserPoint):
        """ê²€ì¶œ ê²°ê³¼ ì‹œê°í™” ì €ì¥"""
        # ì°¨ì´ ì´ë¯¸ì§€
        diff = cv2.absdiff(on_img, off_img)
        
        # ë§ˆí‚¹
        marked_img = on_img.copy()
        cv2.circle(marked_img, (point.x, point.y), 10, (0, 255, 0), 2)
        cv2.circle(marked_img, (point.x, point.y), 1, (0, 0, 255), -1)
        
        # ì •ë³´ í…ìŠ¤íŠ¸
        text = f"Conf: {point.confidence:.2f}"
        cv2.putText(marked_img, text, (point.x + 15, point.y), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
        
        # ê²°í•© ì´ë¯¸ì§€
        combined = np.hstack([off_img, on_img, diff, marked_img])
        
        # ì €ì¥
        output_path = os.path.join(self.processed_dir, f"detected_{point.image_id}")
        cv2.imwrite(output_path, combined)
    
    def analyze_and_learn(self):
        """ê²€ì¶œëœ í¬ì¸íŠ¸ë“¤ ë¶„ì„ ë° í•™ìŠµ"""
        if len(self.detected_points) < 10:
            print("âš ï¸ ê²€ì¶œëœ í¬ì¸íŠ¸ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ (ìµœì†Œ 10ê°œ í•„ìš”)")
            return False
        
        print("\n=== í•™ìŠµ ì‹œì‘ ===")
        
        # 1. ë°ì´í„° ì¶”ì¶œ
        positions = [(p.x, p.y) for p in self.detected_points]
        brightnesses = [p.brightness for p in self.detected_points]
        green_ratios = [p.green_ratio for p in self.detected_points]
        contrasts = [p.contrast for p in self.detected_points]
        confidences = [p.confidence for p in self.detected_points]
        
        # 2. ì´ìƒì¹˜ ì œê±° ë¡œì§ (ìˆ˜ì •ëœ ë¶€ë¶„)
        # ëª¨ë“  ê²€ì¶œ í¬ì¸íŠ¸ë¥¼ ìœ íš¨í•œ(valid) ë°ì´í„°ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
        print("âœ… ëª¨ë“  ê²€ì¶œ í¬ì¸íŠ¸ë¥¼ í•™ìŠµì— ì‚¬ìš©í•©ë‹ˆë‹¤ (ì´ìƒì¹˜ ì œê±° ë¹„í™œì„±í™”).")
        valid_positions = np.array(positions)
        valid_brightnesses = brightnesses
        valid_green_ratios = green_ratios
        valid_contrasts = contrasts
        
        # 3. í†µê³„ ê³„ì‚°
        self.learned_params['avg_position'] = tuple(np.mean(valid_positions, axis=0).astype(int))
        self.learned_params['position_std'] = np.std(valid_positions)
        
        # 4. ë²”ìœ„ ê³„ì‚° (í‰ê·  Â± 2Ïƒ)
        bright_mean, bright_std = np.mean(valid_brightnesses), np.std(valid_brightnesses)
        self.learned_params['brightness_range'] = (
            max(0, bright_mean - 2*bright_std),
            min(255, bright_mean + 2*bright_std)
        )
        
        green_mean, green_std = np.mean(valid_green_ratios), np.std(valid_green_ratios)
        self.learned_params['green_ratio_range'] = (
            max(0, green_mean - 2*green_std),
            min(1.0, green_mean + 2*green_std)
        )
        
        contrast_mean, contrast_std = np.mean(valid_contrasts), np.std(valid_contrasts)
        self.learned_params['contrast_range'] = (
            max(0, contrast_mean - 2*contrast_std),
            contrast_mean + 2*contrast_std
        )
        
        # 5. ì‹ ë¢°ë„ ì„ê³„ê°’
        self.learned_params['confidence_threshold'] = np.percentile(confidences, 30)
        
        # 6. í†µê³„ ì—…ë°ì´íŠ¸
        self.stats['avg_confidence'] = np.mean(confidences)
        
        print("\nğŸ“Š í•™ìŠµëœ íŒŒë¼ë¯¸í„°:")
        print(f"  í‰ê·  ìœ„ì¹˜: {self.learned_params['avg_position']}")
        print(f"  ìœ„ì¹˜ í‘œì¤€í¸ì°¨: {self.learned_params['position_std']:.1f} pixels")
        print(f"  ë°ê¸° ë²”ìœ„: {self.learned_params['brightness_range'][0]:.0f} ~ {self.learned_params['brightness_range'][1]:.0f}")
        print(f"  ë…¹ìƒ‰ë¹„ìœ¨ ë²”ìœ„: {self.learned_params['green_ratio_range'][0]:.2f} ~ {self.learned_params['green_ratio_range'][1]:.2f}")
        print(f"  ëŒ€ë¹„ ë²”ìœ„: {self.learned_params['contrast_range'][0]:.0f} ~ {self.learned_params['contrast_range'][1]:.0f}")
        print(f"  ì‹ ë¢°ë„ ì„ê³„ê°’: {self.learned_params['confidence_threshold']:.2f}")
        
        return True
    
    def visualize_results(self):
        """í•™ìŠµ ê²°ê³¼ ì‹œê°í™” (ì˜ë¬¸ ë²„ì „)"""
        if len(self.detected_points) == 0:
            print("No data to visualize.")
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle('Laser Detection Learning Analysis', fontsize=16)
        
        # 1. ìœ„ì¹˜ ë¶„í¬ (Location Distribution)
        positions = [(p.x, p.y) for p in self.detected_points]
        x_coords = [p[0] for p in positions]
        y_coords = [p[1] for p in positions]
        
        axes[0, 0].scatter(x_coords, y_coords, alpha=0.5)
        axes[0, 0].set_title('Laser Position Distribution')
        axes[0, 0].set_xlabel('X Coordinate')
        axes[0, 0].set_ylabel('Y Coordinate')
        axes[0, 0].invert_yaxis()
        axes[0, 0].grid(True, linestyle='--', alpha=0.6)
        
        # 2. ë°ê¸° íˆìŠ¤í† ê·¸ë¨ (Brightness Histogram)
        brightnesses = [p.brightness for p in self.detected_points]
        axes[0, 1].hist(brightnesses, bins=25, edgecolor='black')
        axes[0, 1].set_title('Brightness Distribution')
        axes[0, 1].set_xlabel('Brightness Value')
        axes[0, 1].axvline(self.learned_params['brightness_range'][0], color='r', linestyle='--', label=f"Min: {self.learned_params['brightness_range'][0]:.0f}")
        axes[0, 1].axvline(self.learned_params['brightness_range'][1], color='r', linestyle='--', label=f"Max: {self.learned_params['brightness_range'][1]:.0f}")
        axes[0, 1].legend()
        
        # 3. ë…¹ìƒ‰ ë¹„ìœ¨ (Green Ratio)
        green_ratios = [p.green_ratio for p in self.detected_points]
        axes[0, 2].hist(green_ratios, bins=25, edgecolor='black', color='green')
        axes[0, 2].set_title('Green Ratio Distribution')
        axes[0, 2].set_xlabel('Green Channel Ratio')
        
        # 4. ëŒ€ë¹„ (Contrast)
        contrasts = [p.contrast for p in self.detected_points]
        axes[1, 0].hist(contrasts, bins=25, edgecolor='black', color='orange')
        axes[1, 0].set_title('Contrast Distribution')
        axes[1, 0].set_xlabel('Contrast (ON - OFF Brightness)')
        
        # 5. ì‹ ë¢°ë„ (Confidence)
        confidences = [p.confidence for p in self.detected_points]
        axes[1, 1].hist(confidences, bins=25, edgecolor='black', color='purple')
        axes[1, 1].set_title('Confidence Score Distribution')
        axes[1, 1].set_xlabel('Confidence')
        axes[1, 1].axvline(self.learned_params['confidence_threshold'], color='r', linestyle='--', label=f"Threshold: {self.learned_params['confidence_threshold']:.2f}")
        axes[1, 1].legend()
        
        # 6. ì‹œê°„ë³„ ì‹ ë¢°ë„ (Confidence over Time)
        axes[1, 2].plot(confidences, 'o-', alpha=0.5)
        axes[1, 2].set_title('Confidence per Detection Order')
        axes[1, 2].set_xlabel('Image Index')
        axes[1, 2].set_ylabel('Confidence Score')
        axes[1, 2].axhline(self.learned_params['confidence_threshold'], color='r', linestyle='--', label=f"Threshold")
        axes[1, 2].grid(True, linestyle='--', alpha=0.6)
        
        plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for suptitle
        self.fig = fig
        # plt.savefig('results/learning_analysis.png', dpi=150) # process_experiments.pyì—ì„œ ì €ì¥í•˜ë¯€ë¡œ ì—¬ê¸°ì„  í•„ìš” ì—†ìŒ
        # plt.show()
    
    def save_model(self, model_path: str = "models/laser_model.pkl"):
        """í•™ìŠµëœ ëª¨ë¸ ì €ì¥"""
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        
        model_data = {
            'params': self.learned_params,
            'stats': self.stats,
            'detected_points': [asdict(p) for p in self.detected_points],
            'timestamp': datetime.now().isoformat()
        }
        
        # Pickle ì €ì¥
        with open(model_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        # JSON ë°±ì—… (ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆìŒ)
        json_path = model_path.replace('.pkl', '.json')
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(model_data, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")
    
    def load_model(self, model_path: str = "models/laser_model.pkl") -> bool:
        """ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(model_path):
            print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            return False
        
        try:
            with open(model_path, 'rb') as f:
                model_data = pickle.load(f)
            
            self.learned_params = model_data['params']
            self.stats = model_data['stats']
            self.detected_points = [LaserPoint(**p) for p in model_data['detected_points']]
            
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            print(f"  í•™ìŠµ ì‹œê°„: {model_data['timestamp']}")
            print(f"  ê²€ì¶œ í¬ì¸íŠ¸: {len(self.detected_points)}ê°œ")
            
            return True
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def test_on_new_image(self, on_img: np.ndarray, off_img: np.ndarray) -> Optional[Tuple[int, int]]:
        """í•™ìŠµëœ íŒŒë¼ë¯¸í„°ë¡œ ìƒˆ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸"""
        point = self.detect_laser_difference(on_img, off_img)
        
        if point and point.confidence >= self.learned_params['confidence_threshold']:
            # í•™ìŠµëœ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
            if (self.learned_params['brightness_range'][0] <= point.brightness <= self.learned_params['brightness_range'][1] and
                self.learned_params['green_ratio_range'][0] <= point.green_ratio <= self.learned_params['green_ratio_range'][1]):
                return (point.x, point.y)
        
        return None


# ë©”ì¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    print("=== ë ˆì´ì € ìë™ í•™ìŠµ ì‹œìŠ¤í…œ ===")
    
    # 1. í•™ìŠµê¸° ì´ˆê¸°í™”
    learner = LaserAutoLearner(data_dir="./data")
    
    # 2. ëª¨ë“  ì´ë¯¸ì§€ ìŒ ì²˜ë¦¬
    learner.process_all_pairs()
    
    # 3. ë¶„ì„ ë° í•™ìŠµ
    if learner.analyze_and_learn():
        # 4. ê²°ê³¼ ì‹œê°í™”
        learner.visualize_results()
        
        # 5. ëª¨ë¸ ì €ì¥
        learner.save_model()
        
        print("\nâœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"ì´ {learner.stats['detected_count']}ê°œ í¬ì¸íŠ¸ì—ì„œ í•™ìŠµ")
        print(f"í‰ê·  ì‹ ë¢°ë„: {learner.stats['avg_confidence']:.2f}")
    else:
        print("\nâŒ í•™ìŠµ ì‹¤íŒ¨ - ë°ì´í„° ë¶€ì¡±")